{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Desertfeng/Sentiment_Analysis-Based-on-BERT/blob/main/In_Depth_Exploration_of_Sentiment_Analysis_Based_on_BERT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "wi2tvRVS1kgW"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import torch\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sv9pplaPKk6s"
      },
      "outputs": [],
      "source": [
        "!pip install accelerate\n",
        "!pip install transformers[torch]\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
        "from torch.utils.data import Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P19DX11FCAmg",
        "outputId": "076f17a4-3012-40f0-f43b-d02787086116"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "p2R_LVSxI71t"
      },
      "outputs": [],
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_path = '/content/gdrive/MyDrive/MLA2/sentiment140.csv'"
      ],
      "metadata": {
        "id": "AfprC_kJA3K-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_path = '/content/gdrive/MyDrive/MLA2/sentiment140.csv' #If can not access google drive, use loacl path instead"
      ],
      "metadata": {
        "id": "sdJot7daA4tq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "ghy27Mfw1lqv"
      },
      "outputs": [],
      "source": [
        "data_path = '/content/gdrive/MyDrive/MLA2/sentiment140.csv'\n",
        "column_names = ['target', 'ids', 'date', 'flag', 'user', 'text']\n",
        "df = pd.read_csv(data_path, encoding='ISO-8859-1', names=column_names)\n",
        "df = df[['target', 'text']]\n",
        "df['target'] = df['target'].map({0: 0, 4: 1})\n",
        "df_sampled = df.sample(frac=0.2, random_state=42)\n",
        "\n",
        "# 使用这个子集替换原始数据集\n",
        "df = df_sampled.reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "_OZf8gb032WI"
      },
      "outputs": [],
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "NHSlzFPA4XQp"
      },
      "outputs": [],
      "source": [
        "def tokenize_function(examples):\n",
        "    return tokenizer(examples['text'].tolist(), padding='max_length', truncation=True, max_length=128)\n",
        "\n",
        "tokenized_datasets = tokenize_function(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "yhwcYpx8JAm4"
      },
      "outputs": [],
      "source": [
        "labels = df['target'].tolist()\n",
        "num_samples = len(df)\n",
        "train_encodings = {key: value[:int(0.9 * num_samples)] for key, value in tokenized_datasets.items()}\n",
        "train_labels = labels[:int(0.9 * num_samples)]\n",
        "val_encodings = {key: value[int(0.9 * num_samples):] for key, value in tokenized_datasets.items()}\n",
        "val_labels = labels[int(0.9 * num_samples):]\n",
        "\n",
        "train_dataset = CustomDataset(train_encodings, train_labels)\n",
        "val_dataset = CustomDataset(val_encodings, val_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZvoUNkrb9Cgm",
        "outputId": "ded6407d-3650-4c89-c389-d9bb55b1839e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "# 4. 初始化模型\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 568
        },
        "id": "TBcjICEH9H_I",
        "outputId": "9013c443-0065-4ca2-e831-f7e4055f712e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='72000' max='72000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [72000/72000 2:01:13, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>5000</td>\n",
              "      <td>0.398300</td>\n",
              "      <td>0.381106</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10000</td>\n",
              "      <td>0.399700</td>\n",
              "      <td>0.362351</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15000</td>\n",
              "      <td>0.375100</td>\n",
              "      <td>0.388362</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20000</td>\n",
              "      <td>0.356100</td>\n",
              "      <td>0.358346</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25000</td>\n",
              "      <td>0.352000</td>\n",
              "      <td>0.355220</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30000</td>\n",
              "      <td>0.356200</td>\n",
              "      <td>0.345483</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>35000</td>\n",
              "      <td>0.353400</td>\n",
              "      <td>0.369384</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40000</td>\n",
              "      <td>0.306200</td>\n",
              "      <td>0.484612</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>45000</td>\n",
              "      <td>0.310400</td>\n",
              "      <td>0.379376</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50000</td>\n",
              "      <td>0.317900</td>\n",
              "      <td>0.425256</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>55000</td>\n",
              "      <td>0.317000</td>\n",
              "      <td>0.426611</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60000</td>\n",
              "      <td>0.273500</td>\n",
              "      <td>0.435556</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>65000</td>\n",
              "      <td>0.300500</td>\n",
              "      <td>0.430225</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>70000</td>\n",
              "      <td>0.301000</td>\n",
              "      <td>0.431738</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=72000, training_loss=0.34102473576863607, metrics={'train_runtime': 7273.8754, 'train_samples_per_second': 79.187, 'train_steps_per_second': 9.898, 'total_flos': 3.788799197184e+16, 'train_loss': 0.34102473576863607, 'epoch': 2.0})"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "# 5. 设置训练参数和开始训练\n",
        "training_args = TrainingArguments(\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    num_train_epochs=2,\n",
        "    evaluation_strategy=\"steps\",\n",
        "    save_steps=5000,\n",
        "    eval_steps=5000,\n",
        "    logging_steps=500,\n",
        "    learning_rate=2e-5,\n",
        "    output_dir=\"./results\",\n",
        "    do_train=True,\n",
        "    do_eval=True,\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    tokenizer=tokenizer,\n",
        ")\n",
        "\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "A9r3s6sgKkLl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac0aa490-5a1c-4138-8d68-10af6f6b12d7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('gdrive/MyDrive/sentiment_model/tokenizer_config.json',\n",
              " 'gdrive/MyDrive/sentiment_model/special_tokens_map.json',\n",
              " 'gdrive/MyDrive/sentiment_model/vocab.txt',\n",
              " 'gdrive/MyDrive/sentiment_model/added_tokens.json')"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "model.save_pretrained('gdrive/MyDrive/sentiment_model')\n",
        "tokenizer.save_pretrained('gdrive/MyDrive/sentiment_model')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "22PL5Q4KJo-C"
      },
      "outputs": [],
      "source": [
        "def sentiment_analysis(sentence):\n",
        "    # 获取模型的设备\n",
        "    device = next(model.parameters()).device\n",
        "\n",
        "    # 对句子进行token化\n",
        "    inputs = tokenizer(sentence, return_tensors=\"pt\", truncation=True, padding=True, max_length=128)\n",
        "\n",
        "    # 将输入数据移动到模型所在的设备\n",
        "    inputs = {name: tensor.to(device) for name, tensor in inputs.items()}\n",
        "\n",
        "    # 使用模型进行预测\n",
        "    with torch.no_grad():\n",
        "        logits = model(**inputs).logits\n",
        "\n",
        "    # 获取预测结果\n",
        "    pred = torch.argmax(logits, dim=1).item()\n",
        "\n",
        "    # 根据预测结果返回情感\n",
        "    if pred == 0:\n",
        "        return \"Negative Sentiment\"\n",
        "    else:\n",
        "        return \"Positive Sentiment\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 新段落"
      ],
      "metadata": {
        "id": "ot1pRZsN8pR6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "FRdCbAp0JpR2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee6fe0e0-3acb-4ff4-b7f6-266db28adc65"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please enter a sentence for sentiment analysis: 1\n",
            "The sentiment of the sentence is: Negative Sentiment\n"
          ]
        }
      ],
      "source": [
        "sentence = input(\"Please enter a sentence for sentiment analysis: \")\n",
        "result = sentiment_analysis(sentence)\n",
        "print(f\"The sentiment of the sentence is: {result}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "2XR9cnHR9XlG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c74d8ae-d4c7-4cc5-85cc-de1142595935"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ],
      "source": [
        "model = BertForSequenceClassification.from_pretrained('gdrive/MyDrive/sentiment_model')\n",
        "tokenizer = BertTokenizer.from_pretrained('gdrive/MyDrive/sentiment_model')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = BertForSequenceClassification.from_pretrained('gdrive/MyDrive/sentiment_model')\n",
        "tokenizer = BertTokenizer.from_pretrained('gdrive/MyDrive/sentiment_model') #If can not access google drive, use loacl path instead"
      ],
      "metadata": {
        "id": "qYhlae93BKWI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sentiment_analysis(sentence):\n",
        "    # 对句子进行token化\n",
        "    inputs = tokenizer(sentence, return_tensors=\"pt\", truncation=True, padding=True, max_length=128)\n",
        "\n",
        "    # 使用模型进行预测\n",
        "    with torch.no_grad():\n",
        "        logits = model(**inputs).logits\n",
        "\n",
        "    # 获取预测结果\n",
        "    pred = torch.argmax(logits, dim=1).item()\n",
        "\n",
        "    # 根据预测结果返回情感\n",
        "    if pred == 0:\n",
        "        return \"Negative Sentiment\"\n",
        "    else:\n",
        "        return \"Positive Sentiment\"\n",
        "\n",
        "# 使用方法：\n",
        "sentence = input(\"Please enter a sentence for sentiment analysis: \")\n",
        "result = sentiment_analysis(sentence)\n",
        "print(f\"The sentiment of the sentence is: {result}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "IuKGhv6Fj80l",
        "outputId": "83c5c156-e057-4d1f-a917-69759d809f9a"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-45-407d1096d34b>\u001b[0m in \u001b[0;36m<cell line: 19>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# 使用方法：\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0msentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Please enter a sentence for sentiment analysis: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msentiment_analysis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"The sentiment of the sentence is: {result}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    849\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m             )\n\u001b[0;32m--> 851\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    852\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers[torch]\n",
        "!pip install sklearn\n"
      ],
      "metadata": {
        "id": "cFhJ6aaNARcL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
        "from torch.utils.data import Dataset\n",
        "import torch\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "import pandas as pd\n",
        "\n",
        "# 加载模型和tokenizer\n",
        "model_path = 'gdrive/MyDrive/sentiment_model'\n",
        "model = BertForSequenceClassification.from_pretrained(model_path)\n",
        "tokenizer = BertTokenizer.from_pretrained(model_path)\n",
        "\n",
        "\n",
        "\n",
        "# 创建一个Trainer实例，用于评估\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=lambda eval_pred: {\"dummy_metric\": 0},  # 后面手动计算指标\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Fn_qUYa-Xoc",
        "outputId": "7a22f33c-5066-44cc-9e35-292ff98fd8eb"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 获取预测结果\n",
        "predictions = trainer.predict(val_dataset)\n",
        "preds = predictions.predictions.argmax(-1)  # 获取每个样本的预测类别\n",
        "\n",
        "# 计算指标\n",
        "accuracy = accuracy_score(val_labels, preds)\n",
        "precision, recall, f1, _ = precision_recall_fscore_support(val_labels, preds, average='binary')\n",
        "\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(f\"Precision: {precision}\")\n",
        "print(f\"Recall: {recall}\")\n",
        "print(f\"F1 Score: {f1}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "id": "BOtr9ndXFxws",
        "outputId": "29b44b9f-df15-44ac-a078-c66e9aef6205"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.86571875\n",
            "Precision: 0.8694940850742512\n",
            "Recall: 0.8614176173555265\n",
            "F1 Score: 0.8654370087370432\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "history_visible": true,
      "mount_file_id": "1NBctTZNGF6xd_1rchlnTDIv_JJpNdlWn",
      "authorship_tag": "ABX9TyNP91ZfmmloJz4wBT6vdYCc",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}